{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzj/anaconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained = True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_s1 = torch.nn.Sequential(*[model.get_submodule('conv1'), model.get_submodule('bn1'), model.get_submodule('relu')])\n",
    "module_s2 = torch.nn.Sequential(*[model.get_submodule('maxpool'), model.get_submodule('layer1')])\n",
    "module_s3 = model.get_submodule('layer2')\n",
    "module_s4 = model.get_submodule('layer3')\n",
    "module_s5 = model.get_submodule('layer4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./test.jpg')\n",
    "image = torchvision.transforms.ToTensor()(image)\n",
    "image = torchvision.transforms.Resize((224, 224))(image)\n",
    "image = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.view(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "feat1 = module_s1(image)\n",
    "feat2 = module_s2(feat1)\n",
    "feat3 = module_s3(feat2)\n",
    "feat4 = module_s4(feat3)\n",
    "feat5 = module_s5(feat4)\n",
    "nrow = 6\n",
    "num = nrow ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(torchvision.utils.make_grid(feat1[0, :num, :, :].view(num, 1, feat1.shape[-2], feat1.shape[-1]), nrow = nrow, normalize = False), './fea1.png')\n",
    "torchvision.utils.save_image(torchvision.utils.make_grid(feat2[0, :num, :, :].view(num, 1, feat2.shape[-2], feat2.shape[-1]), nrow = nrow, normalize = False), './fea2.png')\n",
    "torchvision.utils.save_image(torchvision.utils.make_grid(feat3[0, :num, :, :].view(num, 1, feat3.shape[-2], feat3.shape[-1]), nrow = nrow, normalize = False), './fea3.png')\n",
    "torchvision.utils.save_image(torchvision.utils.make_grid(feat4[0, :num, :, :].view(num, 1, feat4.shape[-2], feat4.shape[-1]), nrow = nrow, normalize = False), './fea4.png')\n",
    "torchvision.utils.save_image(torchvision.utils.make_grid(feat5[0, :num, :, :].view(num, 1, feat5.shape[-2], feat5.shape[-1]), nrow = nrow, normalize = False), './fea5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
